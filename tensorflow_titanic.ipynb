{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reading test and training datasets\n",
    "train = pd.read_csv('train_titanic.csv')\n",
    "test = pd.read_csv('test_titanic.csv')\n",
    "\n",
    "train.index = train['PassengerId']\n",
    "del train['PassengerId']\n",
    "\n",
    "test.index = test['PassengerId']\n",
    "del test['PassengerId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass  \\\n",
       "PassengerId                     \n",
       "1                   0       3   \n",
       "2                   1       1   \n",
       "3                   1       3   \n",
       "4                   1       1   \n",
       "5                   0       3   \n",
       "\n",
       "                                                          Name     Sex   Age  \\\n",
       "PassengerId                                                                    \n",
       "1                                      Braund, Mr. Owen Harris    male  22.0   \n",
       "2            Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
       "3                                       Heikkinen, Miss. Laina  female  26.0   \n",
       "4                 Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n",
       "5                                     Allen, Mr. William Henry    male  35.0   \n",
       "\n",
       "             SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
       "PassengerId                                                          \n",
       "1                1      0         A/5 21171   7.2500   NaN        S  \n",
       "2                1      0          PC 17599  71.2833   C85        C  \n",
       "3                0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "4                1      0            113803  53.1000  C123        S  \n",
       "5                0      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top five line of training dataset\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Removing columns with Name, Ticket and Cabin of datasets\n",
    "train.drop(['Name', 'Ticket', 'Cabin'], axis = 1, inplace=True)\n",
    "test.drop(['Name', 'Ticket', 'Cabin'], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_data_train = pd.get_dummies(train)\n",
    "new_data_test = pd.get_dummies(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass   Age  SibSp  Parch     Fare  Sex_female  Sex_male  \\\n",
       "0          892       3  34.5      0      0   7.8292           0         1   \n",
       "1          893       3  47.0      1      0   7.0000           1         0   \n",
       "2          894       2  62.0      0      0   9.6875           0         1   \n",
       "3          895       3  27.0      0      0   8.6625           0         1   \n",
       "4          896       3  22.0      1      1  12.2875           1         0   \n",
       "\n",
       "   Embarked_C  Embarked_Q  Embarked_S  \n",
       "0           0           1           0  \n",
       "1           0           0           1  \n",
       "2           0           1           0  \n",
       "3           0           0           1  \n",
       "4           0           0           1  "
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top five line of test dataset\n",
    "new_data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass   Age  SibSp  Parch     Fare  Sex_female  \\\n",
       "0            1         0       3  22.0      1      0   7.2500           0   \n",
       "1            2         1       1  38.0      1      0  71.2833           1   \n",
       "2            3         1       3  26.0      0      0   7.9250           1   \n",
       "3            4         1       1  35.0      1      0  53.1000           1   \n",
       "4            5         0       3  35.0      0      0   8.0500           0   \n",
       "\n",
       "   Sex_male  Embarked_C  Embarked_Q  Embarked_S  \n",
       "0         1           0           0           1  \n",
       "1         0           1           0           0  \n",
       "2         0           0           0           1  \n",
       "3         0           0           0           1  \n",
       "4         1           0           0           1  "
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top five line of new training dataset\n",
    "new_data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age           177\n",
       "Embarked_S      0\n",
       "Embarked_Q      0\n",
       "Embarked_C      0\n",
       "Sex_male        0\n",
       "Sex_female      0\n",
       "Fare            0\n",
       "Parch           0\n",
       "SibSp           0\n",
       "Pclass          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Amount of null values in the training set\n",
    "new_data_train.isnull().sum().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filling null values\n",
    "new_data_train['Age'].fillna(new_data_train['Age'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age           86\n",
       "Fare           1\n",
       "Embarked_S     0\n",
       "Embarked_Q     0\n",
       "Embarked_C     0\n",
       "Sex_male       0\n",
       "Sex_female     0\n",
       "Parch          0\n",
       "SibSp          0\n",
       "Pclass         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Amount of null values in the test dataset\n",
    "new_data_test.isnull().sum().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Filling null values\n",
    "new_data_test['Fare'].fillna(new_data_train['Fare'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Separating features and targets for model creation\n",
    "Amount of null values in the test dataset\n",
    "train_features = new_data_train.drop(['Survived'], axis=1) # Features\n",
    "train_labels = new_data_train['Survived'] # Targets\n",
    "\n",
    "# Normalization of data train\n",
    "train_features = (train_features - train_features.mean()) / (train_features.max() - train_features.min())\n",
    "train_features['Age'].fillna(train_features['Age'].mean(), inplace=True)\n",
    "\n",
    "# Normalization of data test\n",
    "test_features = (new_data_test - new_data_test.mean()) / (new_data_test.max() - new_data_test.min()) # Features\n",
    "test_features['Age'].fillna(test_features['Age'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get randomized datasets for training and validation\n",
    "train_features, valid_features, train_labels, valid_labels = train_test_split(\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    test_size=0.15,\n",
    "    random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Number of lines of dataset\n",
    "features_count = train_features.shape[1]\n",
    "# All the labels\n",
    "labels_count = 2\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# TODO: Set the features and labels tensors\n",
    "features = tf.placeholder(tf.float32)\n",
    "labels = tf.placeholder(tf.float32)\n",
    "\n",
    "# TODO: Set the weights and biases tensors\n",
    "weights = tf.Variable(tf.truncated_normal((features_count, labels_count)), name=\"weights\")\n",
    "biases = tf.Variable(tf.zeros([labels_count]), name=\"biases\")\n",
    "\n",
    "# Feed dicts for training, validation, and test session\n",
    "train_feed_dict = {features: train_features.as_matrix(), labels: pd.get_dummies(train_labels).as_matrix()}\n",
    "valid_feed_dict = {features: valid_features.as_matrix(), labels: pd.get_dummies(valid_labels).as_matrix()}\n",
    "test_feed_dict = {features: test_features.as_matrix(), labels: None}\n",
    "\n",
    "# Linear Function WX + b\n",
    "logits = tf.matmul(features, weights) + biases\n",
    "\n",
    "prediction = tf.nn.softmax(logits)\n",
    "\n",
    "# Cross entropy\n",
    "cross_entropy = -tf.reduce_sum(labels * tf.log(prediction), reduction_indices=1)\n",
    "\n",
    "# Training loss\n",
    "loss = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "# Create an operation that initializes all variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Determine if the predictions are correct\n",
    "is_correct_prediction = tf.equal(tf.argmax(prediction, 1), tf.argmax(labels, 1))\n",
    "# Calculate the accuracy of the predictions\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 100/100 Loss: 0.5895808339118958: 100%|██████████| 4/4 [01:26<00:00, 21.55s/batches]\n",
      "Epoch  1/200 Loss: 0.7476343512535095: 100%|██████████| 4/4 [00:00<00:00, 244.02batches/s]\n",
      "Epoch  2/200 Loss: 0.6869530081748962: 100%|██████████| 4/4 [00:00<00:00, 116.44batches/s]\n",
      "Epoch  3/200 Loss: 0.6430153846740723: 100%|██████████| 4/4 [00:00<00:00, 98.93batches/s]\n",
      "Epoch  4/200 Loss: 0.6099739074707031: 100%|██████████| 4/4 [00:00<00:00, 91.72batches/s]\n",
      "Epoch  5/200 Loss: 0.584405779838562: 100%|██████████| 4/4 [00:00<00:00, 99.50batches/s]\n",
      "Epoch  6/200 Loss: 0.5641869902610779: 100%|██████████| 4/4 [00:00<00:00, 121.85batches/s]\n",
      "Epoch  7/200 Loss: 0.5479206442832947: 100%|██████████| 4/4 [00:00<00:00, 127.60batches/s]\n",
      "Epoch  8/200 Loss: 0.5346453785896301: 100%|██████████| 4/4 [00:00<00:00, 137.96batches/s]\n",
      "Epoch  9/200 Loss: 0.5236777067184448: 100%|██████████| 4/4 [00:00<00:00, 115.97batches/s]\n",
      "Epoch 10/200 Loss: 0.514519453048706: 100%|██████████| 4/4 [00:00<00:00, 113.49batches/s]\n",
      "Epoch 11/200 Loss: 0.5068005919456482: 100%|██████████| 4/4 [00:00<00:00, 101.30batches/s]\n",
      "Epoch 12/200 Loss: 0.5002415776252747: 100%|██████████| 4/4 [00:00<00:00, 99.99batches/s]\n",
      "Epoch 13/200 Loss: 0.49462777376174927: 100%|██████████| 4/4 [00:00<00:00, 111.78batches/s]\n",
      "Epoch 14/200 Loss: 0.4897926449775696: 100%|██████████| 4/4 [00:00<00:00, 247.91batches/s]\n",
      "Epoch 15/200 Loss: 0.48560431599617004: 100%|██████████| 4/4 [00:00<00:00, 133.44batches/s]\n",
      "Epoch 16/200 Loss: 0.4819577932357788: 100%|██████████| 4/4 [00:00<00:00, 143.67batches/s]\n",
      "Epoch 17/200 Loss: 0.47876811027526855: 100%|██████████| 4/4 [00:00<00:00, 123.44batches/s]\n",
      "Epoch 18/200 Loss: 0.4759663939476013: 100%|██████████| 4/4 [00:00<00:00, 176.05batches/s]\n",
      "Epoch 19/200 Loss: 0.47349533438682556: 100%|██████████| 4/4 [00:00<00:00, 127.44batches/s]\n",
      "Epoch 20/200 Loss: 0.47130778431892395: 100%|██████████| 4/4 [00:00<00:00, 154.62batches/s]\n",
      "Epoch 21/200 Loss: 0.46936434507369995: 100%|██████████| 4/4 [00:00<00:00, 165.93batches/s]\n",
      "Epoch 22/200 Loss: 0.4676317274570465: 100%|██████████| 4/4 [00:00<00:00, 153.83batches/s]\n",
      "Epoch 23/200 Loss: 0.46608173847198486: 100%|██████████| 4/4 [00:00<00:00, 176.57batches/s]\n",
      "Epoch 24/200 Loss: 0.4646908640861511: 100%|██████████| 4/4 [00:00<00:00, 157.94batches/s]\n",
      "Epoch 25/200 Loss: 0.4634382426738739: 100%|██████████| 4/4 [00:00<00:00, 168.11batches/s]\n",
      "Epoch 26/200 Loss: 0.46230676770210266: 100%|██████████| 4/4 [00:00<00:00, 161.37batches/s]\n",
      "Epoch 27/200 Loss: 0.46128135919570923: 100%|██████████| 4/4 [00:00<00:00, 158.55batches/s]\n",
      "Epoch 28/200 Loss: 0.460348904132843: 100%|██████████| 4/4 [00:00<00:00, 156.37batches/s]\n",
      "Epoch 29/200 Loss: 0.45949840545654297: 100%|██████████| 4/4 [00:00<00:00, 126.29batches/s]\n",
      "Epoch 30/200 Loss: 0.45872005820274353: 100%|██████████| 4/4 [00:00<00:00, 124.20batches/s]\n",
      "Epoch 31/200 Loss: 0.45800551772117615: 100%|██████████| 4/4 [00:00<00:00, 141.42batches/s]\n",
      "Epoch 32/200 Loss: 0.4573473036289215: 100%|██████████| 4/4 [00:00<00:00, 163.47batches/s]\n",
      "Epoch 33/200 Loss: 0.4567390978336334: 100%|██████████| 4/4 [00:00<00:00, 163.86batches/s]\n",
      "Epoch 34/200 Loss: 0.456175297498703: 100%|██████████| 4/4 [00:00<00:00, 201.48batches/s]\n",
      "Epoch 35/200 Loss: 0.45565077662467957: 100%|██████████| 4/4 [00:00<00:00, 173.82batches/s]\n",
      "Epoch 36/200 Loss: 0.455161452293396: 100%|██████████| 4/4 [00:00<00:00, 222.00batches/s]\n",
      "Epoch 37/200 Loss: 0.4547034502029419: 100%|██████████| 4/4 [00:00<00:00, 207.37batches/s]\n",
      "Epoch 38/200 Loss: 0.45427343249320984: 100%|██████████| 4/4 [00:00<00:00, 214.09batches/s]\n",
      "Epoch 39/200 Loss: 0.45386841893196106: 100%|██████████| 4/4 [00:00<00:00, 230.16batches/s]\n",
      "Epoch 40/200 Loss: 0.4534858763217926: 100%|██████████| 4/4 [00:00<00:00, 263.71batches/s]\n",
      "Epoch 41/200 Loss: 0.4531233608722687: 100%|██████████| 4/4 [00:00<00:00, 172.01batches/s]\n",
      "Epoch 42/200 Loss: 0.45277899503707886: 100%|██████████| 4/4 [00:00<00:00, 495.84batches/s]\n",
      "Epoch 43/200 Loss: 0.45245078206062317: 100%|██████████| 4/4 [00:00<00:00, 180.34batches/s]\n",
      "Epoch 44/200 Loss: 0.4521373212337494: 100%|██████████| 4/4 [00:00<00:00, 464.05batches/s]\n",
      "Epoch 45/200 Loss: 0.4518371522426605: 100%|██████████| 4/4 [00:00<00:00, 152.65batches/s]\n",
      "Epoch 46/200 Loss: 0.4515487849712372: 100%|██████████| 4/4 [00:00<00:00, 509.03batches/s]\n",
      "Epoch 47/200 Loss: 0.4512714445590973: 100%|██████████| 4/4 [00:00<00:00, 247.85batches/s]\n",
      "Epoch 48/200 Loss: 0.4510038197040558: 100%|██████████| 4/4 [00:00<00:00, 313.04batches/s]\n",
      "Epoch 49/200 Loss: 0.45074522495269775: 100%|██████████| 4/4 [00:00<00:00, 452.08batches/s]\n",
      "Epoch 50/200 Loss: 0.4504947066307068: 100%|██████████| 4/4 [00:00<00:00, 166.28batches/s]\n",
      "Epoch 51/200 Loss: 0.45025163888931274: 100%|██████████| 4/4 [00:00<00:00, 445.57batches/s]\n",
      "Epoch 52/200 Loss: 0.4500153660774231: 100%|██████████| 4/4 [00:00<00:00, 488.16batches/s]\n",
      "Epoch 53/200 Loss: 0.4497853219509125: 100%|██████████| 4/4 [00:00<00:00, 456.00batches/s]\n",
      "Epoch 54/200 Loss: 0.4495609998703003: 100%|██████████| 4/4 [00:00<00:00, 175.24batches/s]\n",
      "Epoch 55/200 Loss: 0.4493420422077179: 100%|██████████| 4/4 [00:00<00:00, 485.97batches/s]\n",
      "Epoch 56/200 Loss: 0.449127733707428: 100%|██████████| 4/4 [00:00<00:00, 516.32batches/s]\n",
      "Epoch 57/200 Loss: 0.44891810417175293: 100%|██████████| 4/4 [00:00<00:00, 513.82batches/s]\n",
      "Epoch 58/200 Loss: 0.4487125873565674: 100%|██████████| 4/4 [00:00<00:00, 501.13batches/s]\n",
      "Epoch 59/200 Loss: 0.4485108554363251: 100%|██████████| 4/4 [00:00<00:00, 182.02batches/s]\n",
      "Epoch 60/200 Loss: 0.4483128488063812: 100%|██████████| 4/4 [00:00<00:00, 497.83batches/s]\n",
      "Epoch 61/200 Loss: 0.4481182098388672: 100%|██████████| 4/4 [00:00<00:00, 476.87batches/s]\n",
      "Epoch 62/200 Loss: 0.44792667031288147: 100%|██████████| 4/4 [00:00<00:00, 499.68batches/s]\n",
      "Epoch 63/200 Loss: 0.4477381706237793: 100%|██████████| 4/4 [00:00<00:00, 452.08batches/s]\n",
      "Epoch 64/200 Loss: 0.44755232334136963: 100%|██████████| 4/4 [00:00<00:00, 490.85batches/s]\n",
      "Epoch 65/200 Loss: 0.4473690688610077: 100%|██████████| 4/4 [00:00<00:00, 457.56batches/s]\n",
      "Epoch 66/200 Loss: 0.44718846678733826: 100%|██████████| 4/4 [00:00<00:00, 297.95batches/s]\n",
      "Epoch 67/200 Loss: 0.44701021909713745: 100%|██████████| 4/4 [00:00<00:00, 385.73batches/s]\n",
      "Epoch 68/200 Loss: 0.44683414697647095: 100%|██████████| 4/4 [00:00<00:00, 485.68batches/s]\n",
      "Epoch 69/200 Loss: 0.44666022062301636: 100%|██████████| 4/4 [00:00<00:00, 539.23batches/s]\n",
      "Epoch 70/200 Loss: 0.44648849964141846: 100%|██████████| 4/4 [00:00<00:00, 517.27batches/s]\n",
      "Epoch 71/200 Loss: 0.44631871581077576: 100%|██████████| 4/4 [00:00<00:00, 524.45batches/s]\n",
      "Epoch 72/200 Loss: 0.4461507201194763: 100%|██████████| 4/4 [00:00<00:00, 502.57batches/s]\n",
      "Epoch 73/200 Loss: 0.4459845721721649: 100%|██████████| 4/4 [00:00<00:00, 523.27batches/s]\n",
      "Epoch 74/200 Loss: 0.44582027196884155: 100%|██████████| 4/4 [00:00<00:00, 263.51batches/s]\n",
      "Epoch 75/200 Loss: 0.4456576704978943: 100%|██████████| 4/4 [00:00<00:00, 320.75batches/s]\n",
      "Epoch 76/200 Loss: 0.44549667835235596: 100%|██████████| 4/4 [00:00<00:00, 553.47batches/s]\n",
      "Epoch 77/200 Loss: 0.4453373849391937: 100%|██████████| 4/4 [00:00<00:00, 537.78batches/s]\n",
      "Epoch 78/200 Loss: 0.4451795518398285: 100%|██████████| 4/4 [00:00<00:00, 523.01batches/s]\n",
      "Epoch 79/200 Loss: 0.4450233578681946: 100%|██████████| 4/4 [00:00<00:00, 536.70batches/s]\n",
      "Epoch 80/200 Loss: 0.44486868381500244: 100%|██████████| 4/4 [00:00<00:00, 570.77batches/s]\n",
      "Epoch 81/200 Loss: 0.4447154700756073: 100%|██████████| 4/4 [00:00<00:00, 528.40batches/s]\n",
      "Epoch 82/200 Loss: 0.44456368684768677: 100%|██████████| 4/4 [00:00<00:00, 548.40batches/s]\n",
      "Epoch 83/200 Loss: 0.44441330432891846: 100%|██████████| 4/4 [00:00<00:00, 486.38batches/s]\n",
      "Epoch 84/200 Loss: 0.44426441192626953: 100%|██████████| 4/4 [00:00<00:00, 548.83batches/s]\n",
      "Epoch 85/200 Loss: 0.4441167116165161: 100%|██████████| 4/4 [00:00<00:00, 508.39batches/s]\n",
      "Epoch 86/200 Loss: 0.4439704120159149: 100%|██████████| 4/4 [00:00<00:00, 296.50batches/s]\n",
      "Epoch 87/200 Loss: 0.4438256025314331: 100%|██████████| 4/4 [00:00<00:00, 484.02batches/s]\n",
      "Epoch 88/200 Loss: 0.4436819851398468: 100%|██████████| 4/4 [00:00<00:00, 504.41batches/s]\n",
      "Epoch 89/200 Loss: 0.44353970885276794: 100%|██████████| 4/4 [00:00<00:00, 233.67batches/s]\n",
      "Epoch 90/200 Loss: 0.44339868426322937: 100%|██████████| 4/4 [00:00<00:00, 362.62batches/s]\n",
      "Epoch 91/200 Loss: 0.44325894117355347: 100%|██████████| 4/4 [00:00<00:00, 539.15batches/s]\n",
      "Epoch 92/200 Loss: 0.44312041997909546: 100%|██████████| 4/4 [00:00<00:00, 513.47batches/s]\n",
      "Epoch 93/200 Loss: 0.4429832100868225: 100%|██████████| 4/4 [00:00<00:00, 544.80batches/s]\n",
      "Epoch 94/200 Loss: 0.44284722208976746: 100%|██████████| 4/4 [00:00<00:00, 482.05batches/s]\n",
      "Epoch 95/200 Loss: 0.44271233677864075: 100%|██████████| 4/4 [00:00<00:00, 528.90batches/s]\n",
      "Epoch 96/200 Loss: 0.4425787329673767: 100%|██████████| 4/4 [00:00<00:00, 496.22batches/s]\n",
      "Epoch 97/200 Loss: 0.4424462914466858: 100%|██████████| 4/4 [00:00<00:00, 465.12batches/s]\n",
      "Epoch 98/200 Loss: 0.44231513142585754: 100%|██████████| 4/4 [00:00<00:00, 468.49batches/s]\n",
      "Epoch 99/200 Loss: 0.44218504428863525: 100%|██████████| 4/4 [00:00<00:00, 506.97batches/s]\n",
      "Epoch 100/200 Loss: 0.4420561194419861: 100%|██████████| 4/4 [00:00<00:00, 520.03batches/s]\n",
      "Epoch 101/200 Loss: 0.4419284164905548: 100%|██████████| 4/4 [00:00<00:00, 499.93batches/s]\n",
      "Epoch 102/200 Loss: 0.4418018162250519: 100%|██████████| 4/4 [00:00<00:00, 541.13batches/s]\n",
      "Epoch 103/200 Loss: 0.44167637825012207: 100%|██████████| 4/4 [00:00<00:00, 507.80batches/s]\n",
      "Epoch 104/200 Loss: 0.441552072763443: 100%|██████████| 4/4 [00:00<00:00, 521.71batches/s]\n",
      "Epoch 105/200 Loss: 0.4414288103580475: 100%|██████████| 4/4 [00:00<00:00, 495.97batches/s]\n",
      "Epoch 106/200 Loss: 0.4413067400455475: 100%|██████████| 4/4 [00:00<00:00, 534.48batches/s]\n",
      "Epoch 107/200 Loss: 0.44118577241897583: 100%|██████████| 4/4 [00:00<00:00, 502.51batches/s]\n",
      "Epoch 108/200 Loss: 0.44106584787368774: 100%|██████████| 4/4 [00:00<00:00, 547.56batches/s]\n",
      "Epoch 109/200 Loss: 0.44094693660736084: 100%|██████████| 4/4 [00:00<00:00, 518.14batches/s]\n",
      "Epoch 110/200 Loss: 0.4408292770385742: 100%|██████████| 4/4 [00:00<00:00, 557.10batches/s]\n",
      "Epoch 111/200 Loss: 0.440712571144104: 100%|██████████| 4/4 [00:00<00:00, 488.09batches/s]\n",
      "Epoch 112/200 Loss: 0.44059690833091736: 100%|██████████| 4/4 [00:00<00:00, 537.49batches/s]\n",
      "Epoch 113/200 Loss: 0.44048237800598145: 100%|██████████| 4/4 [00:00<00:00, 523.42batches/s]\n",
      "Epoch 114/200 Loss: 0.4403688609600067: 100%|██████████| 4/4 [00:00<00:00, 554.71batches/s]\n",
      "Epoch 115/200 Loss: 0.4402562975883484: 100%|██████████| 4/4 [00:00<00:00, 519.21batches/s]\n",
      "Epoch 116/200 Loss: 0.44014492630958557: 100%|██████████| 4/4 [00:00<00:00, 553.70batches/s]\n",
      "Epoch 117/200 Loss: 0.4400344789028168: 100%|██████████| 4/4 [00:00<00:00, 523.42batches/s]\n",
      "Epoch 118/200 Loss: 0.43992501497268677: 100%|██████████| 4/4 [00:00<00:00, 192.72batches/s]\n",
      "Epoch 119/200 Loss: 0.43981656432151794: 100%|██████████| 4/4 [00:00<00:00, 470.81batches/s]\n",
      "Epoch 120/200 Loss: 0.4397091269493103: 100%|██████████| 4/4 [00:00<00:00, 558.27batches/s]\n",
      "Epoch 121/200 Loss: 0.43960264325141907: 100%|██████████| 4/4 [00:00<00:00, 528.13batches/s]\n",
      "Epoch 122/200 Loss: 0.4394972026348114: 100%|██████████| 4/4 [00:00<00:00, 531.63batches/s]\n",
      "Epoch 123/200 Loss: 0.43939268589019775: 100%|██████████| 4/4 [00:00<00:00, 538.65batches/s]\n",
      "Epoch 124/200 Loss: 0.4392892122268677: 100%|██████████| 4/4 [00:00<00:00, 537.28batches/s]\n",
      "Epoch 125/200 Loss: 0.4391867220401764: 100%|██████████| 4/4 [00:00<00:00, 537.71batches/s]\n",
      "Epoch 126/200 Loss: 0.4390850067138672: 100%|██████████| 4/4 [00:00<00:00, 543.55batches/s]\n",
      "Epoch 127/200 Loss: 0.43898436427116394: 100%|██████████| 4/4 [00:00<00:00, 501.32batches/s]\n",
      "Epoch 128/200 Loss: 0.4388846158981323: 100%|██████████| 4/4 [00:00<00:00, 539.67batches/s]\n",
      "Epoch 129/200 Loss: 0.43878576159477234: 100%|██████████| 4/4 [00:00<00:00, 502.25batches/s]\n",
      "Epoch 130/200 Loss: 0.4386879503726959: 100%|██████████| 4/4 [00:00<00:00, 509.23batches/s]\n",
      "Epoch 131/200 Loss: 0.4385908544063568: 100%|██████████| 4/4 [00:00<00:00, 506.65batches/s]\n",
      "Epoch 132/200 Loss: 0.43849483132362366: 100%|██████████| 4/4 [00:00<00:00, 504.15batches/s]\n",
      "Epoch 133/200 Loss: 0.43839964270591736: 100%|██████████| 4/4 [00:00<00:00, 518.20batches/s]\n",
      "Epoch 134/200 Loss: 0.43830540776252747: 100%|██████████| 4/4 [00:00<00:00, 499.13batches/s]\n",
      "Epoch 135/200 Loss: 0.4382118582725525: 100%|██████████| 4/4 [00:00<00:00, 503.77batches/s]\n",
      "Epoch 136/200 Loss: 0.4381193518638611: 100%|██████████| 4/4 [00:00<00:00, 499.05batches/s]\n",
      "Epoch 137/200 Loss: 0.43802767992019653: 100%|██████████| 4/4 [00:00<00:00, 513.02batches/s]\n",
      "Epoch 138/200 Loss: 0.43793681263923645: 100%|██████████| 4/4 [00:00<00:00, 481.81batches/s]\n",
      "Epoch 139/200 Loss: 0.4378468096256256: 100%|██████████| 4/4 [00:00<00:00, 496.22batches/s]\n",
      "Epoch 140/200 Loss: 0.4377577006816864: 100%|██████████| 4/4 [00:00<00:00, 488.82batches/s]\n",
      "Epoch 141/200 Loss: 0.43766939640045166: 100%|██████████| 4/4 [00:00<00:00, 488.22batches/s]\n",
      "Epoch 142/200 Loss: 0.4375818967819214: 100%|██████████| 4/4 [00:00<00:00, 491.40batches/s]\n",
      "Epoch 143/200 Loss: 0.43749529123306274: 100%|██████████| 4/4 [00:00<00:00, 563.39batches/s]\n",
      "Epoch 144/200 Loss: 0.4374094307422638: 100%|██████████| 4/4 [00:00<00:00, 512.75batches/s]\n",
      "Epoch 145/200 Loss: 0.4373243749141693: 100%|██████████| 4/4 [00:00<00:00, 532.20batches/s]\n",
      "Epoch 146/200 Loss: 0.4372401237487793: 100%|██████████| 4/4 [00:00<00:00, 523.01batches/s]\n",
      "Epoch 147/200 Loss: 0.437156617641449: 100%|██████████| 4/4 [00:00<00:00, 487.92batches/s]\n",
      "Epoch 148/200 Loss: 0.4370739758014679: 100%|██████████| 4/4 [00:00<00:00, 536.61batches/s]\n",
      "Epoch 149/200 Loss: 0.4369920492172241: 100%|██████████| 4/4 [00:00<00:00, 486.62batches/s]\n",
      "Epoch 150/200 Loss: 0.4369108974933624: 100%|██████████| 4/4 [00:00<00:00, 518.20batches/s]\n",
      "Epoch 151/200 Loss: 0.4368305206298828: 100%|██████████| 4/4 [00:00<00:00, 470.42batches/s]\n",
      "Epoch 152/200 Loss: 0.4367508590221405: 100%|██████████| 4/4 [00:00<00:00, 575.11batches/s]\n",
      "Epoch 153/200 Loss: 0.43667200207710266: 100%|██████████| 4/4 [00:00<00:00, 527.98batches/s]\n",
      "Epoch 154/200 Loss: 0.4365938603878021: 100%|██████████| 4/4 [00:00<00:00, 569.07batches/s]\n",
      "Epoch 155/200 Loss: 0.4365164339542389: 100%|██████████| 4/4 [00:00<00:00, 493.71batches/s]\n",
      "Epoch 156/200 Loss: 0.43643975257873535: 100%|██████████| 4/4 [00:00<00:00, 522.18batches/s]\n",
      "Epoch 157/200 Loss: 0.4363638460636139: 100%|██████████| 4/4 [00:00<00:00, 485.86batches/s]\n",
      "Epoch 158/200 Loss: 0.4362885653972626: 100%|██████████| 4/4 [00:00<00:00, 502.82batches/s]\n",
      "Epoch 159/200 Loss: 0.43621399998664856: 100%|██████████| 4/4 [00:00<00:00, 506.19batches/s]\n",
      "Epoch 160/200 Loss: 0.43614017963409424: 100%|██████████| 4/4 [00:00<00:00, 480.36batches/s]\n",
      "Epoch 161/200 Loss: 0.43606704473495483: 100%|██████████| 4/4 [00:00<00:00, 508.25batches/s]\n",
      "Epoch 162/200 Loss: 0.43599456548690796: 100%|██████████| 4/4 [00:00<00:00, 487.92batches/s]\n",
      "Epoch 163/200 Loss: 0.4359227418899536: 100%|██████████| 4/4 [00:00<00:00, 525.55batches/s]\n",
      "Epoch 164/200 Loss: 0.43585166335105896: 100%|██████████| 4/4 [00:00<00:00, 495.91batches/s]\n",
      "Epoch 165/200 Loss: 0.4357811510562897: 100%|██████████| 4/4 [00:00<00:00, 524.45batches/s]\n",
      "Epoch 166/200 Loss: 0.4357113242149353: 100%|██████████| 4/4 [00:00<00:00, 497.21batches/s]\n",
      "Epoch 167/200 Loss: 0.43564221262931824: 100%|██████████| 4/4 [00:00<00:00, 498.31batches/s]\n",
      "Epoch 168/200 Loss: 0.4355737566947937: 100%|██████████| 4/4 [00:00<00:00, 469.21batches/s]\n",
      "Epoch 169/200 Loss: 0.43550586700439453: 100%|██████████| 4/4 [00:00<00:00, 523.62batches/s]\n",
      "Epoch 170/200 Loss: 0.4354386031627655: 100%|██████████| 4/4 [00:00<00:00, 557.27batches/s]\n",
      "Epoch 171/200 Loss: 0.435371994972229: 100%|██████████| 4/4 [00:00<00:00, 521.37batches/s]\n",
      "Epoch 172/200 Loss: 0.43530604243278503: 100%|██████████| 4/4 [00:00<00:00, 541.20batches/s]\n",
      "Epoch 173/200 Loss: 0.43524062633514404: 100%|██████████| 4/4 [00:00<00:00, 494.74batches/s]\n",
      "Epoch 174/200 Loss: 0.4351758658885956: 100%|██████████| 4/4 [00:00<00:00, 528.48batches/s]\n",
      "Epoch 175/200 Loss: 0.4351117014884949: 100%|██████████| 4/4 [00:00<00:00, 508.59batches/s]\n",
      "Epoch 176/200 Loss: 0.4350481927394867: 100%|██████████| 4/4 [00:00<00:00, 522.75batches/s]\n",
      "Epoch 177/200 Loss: 0.43498513102531433: 100%|██████████| 4/4 [00:00<00:00, 511.91batches/s]\n",
      "Epoch 178/200 Loss: 0.4349227845668793: 100%|██████████| 4/4 [00:00<00:00, 560.60batches/s]\n",
      "Epoch 179/200 Loss: 0.4348609447479248: 100%|██████████| 4/4 [00:00<00:00, 492.97batches/s]\n",
      "Epoch 180/200 Loss: 0.4347996711730957: 100%|██████████| 4/4 [00:00<00:00, 555.72batches/s]\n",
      "Epoch 181/200 Loss: 0.43473902344703674: 100%|██████████| 4/4 [00:00<00:00, 509.36batches/s]\n",
      "Epoch 182/200 Loss: 0.4346788823604584: 100%|██████████| 4/4 [00:00<00:00, 226.76batches/s]\n",
      "Epoch 183/200 Loss: 0.43461933732032776: 100%|██████████| 4/4 [00:00<00:00, 358.26batches/s]\n",
      "Epoch 184/200 Loss: 0.4345603585243225: 100%|██████████| 4/4 [00:00<00:00, 524.86batches/s]\n",
      "Epoch 185/200 Loss: 0.4345019459724426: 100%|██████████| 4/4 [00:00<00:00, 494.19batches/s]\n",
      "Epoch 186/200 Loss: 0.43444398045539856: 100%|██████████| 4/4 [00:00<00:00, 577.61batches/s]\n",
      "Epoch 187/200 Loss: 0.43438658118247986: 100%|██████████| 4/4 [00:00<00:00, 506.91batches/s]\n",
      "Epoch 188/200 Loss: 0.43432965874671936: 100%|██████████| 4/4 [00:00<00:00, 533.39batches/s]\n",
      "Epoch 189/200 Loss: 0.434273362159729: 100%|██████████| 4/4 [00:00<00:00, 480.82batches/s]\n",
      "Epoch 190/200 Loss: 0.43421757221221924: 100%|██████████| 4/4 [00:00<00:00, 524.24batches/s]\n",
      "Epoch 191/200 Loss: 0.4341621994972229: 100%|██████████| 4/4 [00:00<00:00, 535.04batches/s]\n",
      "Epoch 192/200 Loss: 0.43410730361938477: 100%|██████████| 4/4 [00:00<00:00, 497.63batches/s]\n",
      "Epoch 193/200 Loss: 0.43405306339263916: 100%|██████████| 4/4 [00:00<00:00, 432.16batches/s]\n",
      "Epoch 194/200 Loss: 0.43399927020072937: 100%|██████████| 4/4 [00:00<00:00, 490.98batches/s]\n",
      "Epoch 195/200 Loss: 0.43394601345062256: 100%|██████████| 4/4 [00:00<00:00, 531.14batches/s]\n",
      "Epoch 196/200 Loss: 0.4338931441307068: 100%|██████████| 4/4 [00:00<00:00, 510.60batches/s]\n",
      "Epoch 197/200 Loss: 0.433840811252594: 100%|██████████| 4/4 [00:00<00:00, 531.56batches/s]\n",
      "Epoch 198/200 Loss: 0.43378889560699463: 100%|██████████| 4/4 [00:00<00:00, 496.84batches/s]\n",
      "Epoch 199/200 Loss: 0.43373754620552063: 100%|██████████| 4/4 [00:00<00:00, 583.76batches/s]\n",
      "Epoch 200/200 Loss: 0.43368661403656006:   0%|          | 0/4 [00:00<?, ?batches/s]"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk4AAAGGCAYAAACNCg6xAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlFJKKTf9P22ck0sI3eDDAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11cdd75f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy at 0.8283582329750061\n"
     ]
    }
   ],
   "source": [
    "# Trainning neural network\n",
    "\n",
    "# Change if you have memory restrictions\n",
    "batch_size = 200\n",
    "\n",
    "# TODO: Find the best parameters for each configuration\n",
    "epochs = 200\n",
    "learning_rate = 0.2\n",
    "\n",
    "# Gradient Descent\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)    \n",
    "\n",
    "# The accuracy measured against the validation set\n",
    "validation_accuracy = 0.0\n",
    "\n",
    "# Measurements use for graphing loss and accuracy\n",
    "log_batch_step = 10\n",
    "batches = []\n",
    "loss_batch = []\n",
    "train_acc_batch = []\n",
    "valid_acc_batch = []\n",
    "v_loss = 0\n",
    "\n",
    "with tf.Session() as session:\n",
    "    session.run(init)\n",
    "    batch_count = int(math.ceil(len(train_features)/batch_size))\n",
    "\n",
    "    for epoch_i in range(epochs):        \n",
    "        # The training cycle\n",
    "        for batch_i in batches_pbar:\n",
    "            # Get a batch of training features and labels\n",
    "            batch_start = batch_i*batch_size\n",
    "            batch_features = train_features[batch_start:batch_start + batch_size].as_matrix()\n",
    "            batch_labels = pd.get_dummies(train_labels[batch_start:batch_start + batch_size]).as_matrix()\n",
    "\n",
    "            # Run optimizer and get loss\n",
    "            _, v_loss = session.run(\n",
    "                [optimizer, loss],\n",
    "                feed_dict={features: batch_features, labels: batch_labels})\n",
    "\n",
    "            # Log every count batches\n",
    "            if not batch_i % log_batch_step:\n",
    "                # Calculate Training and Validation accuracy\n",
    "                training_accuracy = session.run(accuracy, feed_dict=train_feed_dict)\n",
    "                validation_accuracy = session.run(accuracy, feed_dict=valid_feed_dict)\n",
    "\n",
    "                # Log batches\n",
    "                previous_batch = batches[-1] if batches else 0\n",
    "                batches.append(log_batch_step + previous_batch)\n",
    "                loss_batch.append(l)\n",
    "                train_acc_batch.append(training_accuracy)\n",
    "                valid_acc_batch.append(validation_accuracy)\n",
    "\n",
    "        # Progress bar\n",
    "        batches_pbar = tqdm(range(batch_count), desc='Epoch {:>2}/{} Loss: {}'.format(epoch_i+1, epochs, v_loss), unit='batches')\n",
    "\n",
    "        # Check accuracy against Validation data\n",
    "        validation_accuracy = session.run(accuracy, feed_dict=valid_feed_dict)\n",
    "\n",
    "\n",
    "loss_plot = plt.subplot(211)\n",
    "loss_plot.set_title('Loss')\n",
    "loss_plot.plot(batches, loss_batch, 'g')\n",
    "loss_plot.set_xlim([batches[0], batches[-1]])\n",
    "acc_plot = plt.subplot(212)\n",
    "acc_plot.set_title('Accuracy')\n",
    "acc_plot.plot(batches, train_acc_batch, 'r', label='Training Accuracy')\n",
    "acc_plot.plot(batches, valid_acc_batch, 'x', label='Validation Accuracy')\n",
    "acc_plot.set_ylim([0, 1.0])\n",
    "acc_plot.set_xlim([batches[0], batches[-1]])\n",
    "acc_plot.legend(loc=4)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('Validation accuracy at {}'.format(validation_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate file to kaggle submission\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    indexes = new_data_test.index.values\n",
    "    test_logits = logits.eval(test_feed_dict)\n",
    "    predictions = tf.argmax(test_logits, dimension=1).eval()\n",
    "\n",
    "    with open(\"submission.csv\", \"w\") as f:\n",
    "        f.write(\"PassengerId,Survived\\n\")\n",
    "        for index, prediction in zip(indexes, predictions):\n",
    "            f.write(\"{0},{1}\\n\".format(index, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
