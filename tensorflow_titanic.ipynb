{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reading test and training datasets\n",
    "train = pd.read_csv('train_titanic.csv')\n",
    "test = pd.read_csv('test_titanic.csv')\n",
    "\n",
    "train.index = train['PassengerId']\n",
    "del train['PassengerId']\n",
    "\n",
    "test.index = test['PassengerId']\n",
    "del test['PassengerId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass  \\\n",
       "PassengerId                     \n",
       "1                   0       3   \n",
       "2                   1       1   \n",
       "3                   1       3   \n",
       "4                   1       1   \n",
       "5                   0       3   \n",
       "\n",
       "                                                          Name     Sex   Age  \\\n",
       "PassengerId                                                                    \n",
       "1                                      Braund, Mr. Owen Harris    male  22.0   \n",
       "2            Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
       "3                                       Heikkinen, Miss. Laina  female  26.0   \n",
       "4                 Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n",
       "5                                     Allen, Mr. William Henry    male  35.0   \n",
       "\n",
       "             SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
       "PassengerId                                                          \n",
       "1                1      0         A/5 21171   7.2500   NaN        S  \n",
       "2                1      0          PC 17599  71.2833   C85        C  \n",
       "3                0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "4                1      0            113803  53.1000  C123        S  \n",
       "5                0      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top five line of training dataset\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Removing columns with Name, Ticket and Cabin of datasets\n",
    "train.drop(['Name', 'Ticket', 'Cabin'], axis = 1, inplace=True)\n",
    "test.drop(['Name', 'Ticket', 'Cabin'], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_data_train = pd.get_dummies(train)\n",
    "new_data_test = pd.get_dummies(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>3</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>3</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>2</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>3</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Pclass   Age  SibSp  Parch     Fare  Sex_female  Sex_male  \\\n",
       "PassengerId                                                              \n",
       "892               3  34.5      0      0   7.8292           0         1   \n",
       "893               3  47.0      1      0   7.0000           1         0   \n",
       "894               2  62.0      0      0   9.6875           0         1   \n",
       "895               3  27.0      0      0   8.6625           0         1   \n",
       "896               3  22.0      1      1  12.2875           1         0   \n",
       "\n",
       "             Embarked_C  Embarked_Q  Embarked_S  \n",
       "PassengerId                                      \n",
       "892                   0           1           0  \n",
       "893                   0           0           1  \n",
       "894                   0           1           0  \n",
       "895                   0           0           1  \n",
       "896                   0           0           1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top five line of test dataset\n",
    "new_data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass   Age  SibSp  Parch     Fare  Sex_female  \\\n",
       "PassengerId                                                              \n",
       "1                   0       3  22.0      1      0   7.2500           0   \n",
       "2                   1       1  38.0      1      0  71.2833           1   \n",
       "3                   1       3  26.0      0      0   7.9250           1   \n",
       "4                   1       1  35.0      1      0  53.1000           1   \n",
       "5                   0       3  35.0      0      0   8.0500           0   \n",
       "\n",
       "             Sex_male  Embarked_C  Embarked_Q  Embarked_S  \n",
       "PassengerId                                                \n",
       "1                   1           0           0           1  \n",
       "2                   0           1           0           0  \n",
       "3                   0           0           0           1  \n",
       "4                   0           0           0           1  \n",
       "5                   1           0           0           1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top five line of new training dataset\n",
    "new_data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age           177\n",
       "Embarked_S      0\n",
       "Embarked_Q      0\n",
       "Embarked_C      0\n",
       "Sex_male        0\n",
       "Sex_female      0\n",
       "Fare            0\n",
       "Parch           0\n",
       "SibSp           0\n",
       "Pclass          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Amount of null values in the training set\n",
    "new_data_train.isnull().sum().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filling null values\n",
    "new_data_train['Age'].fillna(new_data_train['Age'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age           86\n",
       "Fare           1\n",
       "Embarked_S     0\n",
       "Embarked_Q     0\n",
       "Embarked_C     0\n",
       "Sex_male       0\n",
       "Sex_female     0\n",
       "Parch          0\n",
       "SibSp          0\n",
       "Pclass         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Amount of null values in the test dataset\n",
    "new_data_test.isnull().sum().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Filling null values\n",
    "new_data_test['Fare'].fillna(new_data_train['Fare'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Separating features and targets for model creation\n",
    "train_features = new_data_train.drop(['Survived'], axis=1) # Features\n",
    "train_labels = new_data_train['Survived'] # Targets\n",
    "\n",
    "# Normalization of data train\n",
    "train_features = (train_features - train_features.mean()) / (train_features.max() - train_features.min())\n",
    "train_features['Age'].fillna(train_features['Age'].mean(), inplace=True)\n",
    "\n",
    "# Normalization of data test\n",
    "test_features = (new_data_test - new_data_test.mean()) / (new_data_test.max() - new_data_test.min()) # Features\n",
    "test_features['Age'].fillna(test_features['Age'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get randomized datasets for training and validation\n",
    "train_features, valid_features, train_labels, valid_labels = train_test_split(\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    test_size=0.15,\n",
    "    random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Number of lines of dataset\n",
    "features_count = train_features.shape[1]\n",
    "# All the labels\n",
    "labels_count = 2\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Features and labels tensors\n",
    "features = tf.placeholder(tf.float32, name=\"features\")\n",
    "labels = tf.placeholder(tf.float32, name=\"labels\")\n",
    "\n",
    "# Weights and biases tensors\n",
    "weights = tf.Variable(tf.truncated_normal((features_count, labels_count)), name=\"weights\")\n",
    "\n",
    "# Weights with random uniform distribution\n",
    "#layer_1_weight_shape = (features_count, labels_count)\n",
    "#weights = tf.Variable(tf.random_uniform(layer_1_weight_shape, -0.1, 0.1), name=\"weights\")\n",
    "\n",
    "# Weights with truncated normal distribution\n",
    "#layer_1_weight_shape = (features_count, labels_count)\n",
    "#weights = tf.Variable(tf.truncated_normal(layer_1_weight_shape, stddev=0.1), name=\"weights\")\n",
    "\n",
    "biases = tf.Variable(tf.zeros([labels_count]), name=\"biases\")\n",
    "\n",
    "# Feed dicts for training, validation, and test session\n",
    "train_feed_dict = {features: train_features.as_matrix(), labels: pd.get_dummies(train_labels).as_matrix()}\n",
    "valid_feed_dict = {features: valid_features.as_matrix(), labels: pd.get_dummies(valid_labels).as_matrix()}\n",
    "test_feed_dict = {features: test_features.as_matrix(), labels: None}\n",
    "\n",
    "# Linear Function WX + b\n",
    "logits = tf.matmul(features, weights) + biases\n",
    "\n",
    "prediction = tf.nn.softmax(logits)\n",
    "\n",
    "# Cross entropy\n",
    "cross_entropy = -tf.reduce_sum(labels * tf.log(prediction), reduction_indices=1)\n",
    "\n",
    "# Training loss\n",
    "loss = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "# Create an operation that initializes all variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Determine if the predictions are correct\n",
    "is_correct_prediction = tf.equal(tf.argmax(prediction, 1), tf.argmax(labels, 1))\n",
    "# Calculate the accuracy of the predictions\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  1/200 Loss: 0: 100%|██████████| 1/1 [00:00<00:00, 31.53batches/s]\n",
      "Epoch  2/200 Loss: 0.6800912022590637: 100%|██████████| 1/1 [00:00<00:00, 91.02batches/s]\n",
      "Epoch  3/200 Loss: 0.6643237471580505: 100%|██████████| 1/1 [00:00<00:00, 201.42batches/s]\n",
      "Epoch  4/200 Loss: 0.6502372622489929: 100%|██████████| 1/1 [00:00<00:00, 89.96batches/s]\n",
      "Epoch  5/200 Loss: 0.6376083493232727: 100%|██████████| 1/1 [00:00<00:00, 49.92batches/s]\n",
      "Epoch  6/200 Loss: 0.6262454390525818: 100%|██████████| 1/1 [00:00<00:00, 109.93batches/s]\n",
      "Epoch  7/200 Loss: 0.6159846186637878: 100%|██████████| 1/1 [00:00<00:00, 65.79batches/s]\n",
      "Epoch  8/200 Loss: 0.6066857576370239: 100%|██████████| 1/1 [00:00<00:00, 104.00batches/s]\n",
      "Epoch  9/200 Loss: 0.5982294678688049: 100%|██████████| 1/1 [00:00<00:00, 85.68batches/s]\n",
      "Epoch 10/200 Loss: 0.5905130505561829: 100%|██████████| 1/1 [00:00<00:00, 276.40batches/s]\n",
      "Epoch 11/200 Loss: 0.5834491848945618: 100%|██████████| 1/1 [00:00<00:00, 132.27batches/s]\n",
      "Epoch 12/200 Loss: 0.5769622921943665: 100%|██████████| 1/1 [00:00<00:00, 124.70batches/s]\n",
      "Epoch 13/200 Loss: 0.57098788022995: 100%|██████████| 1/1 [00:00<00:00, 336.57batches/s]\n",
      "Epoch 14/200 Loss: 0.5654696822166443: 100%|██████████| 1/1 [00:00<00:00, 315.67batches/s]\n",
      "Epoch 15/200 Loss: 0.5603594779968262: 100%|██████████| 1/1 [00:00<00:00, 131.93batches/s]\n",
      "Epoch 16/200 Loss: 0.5556151270866394: 100%|██████████| 1/1 [00:00<00:00, 130.07batches/s]\n",
      "Epoch 17/200 Loss: 0.5511998534202576: 100%|██████████| 1/1 [00:00<00:00, 286.95batches/s]\n",
      "Epoch 18/200 Loss: 0.5470815300941467: 100%|██████████| 1/1 [00:00<00:00, 385.22batches/s]\n",
      "Epoch 19/200 Loss: 0.5432318449020386: 100%|██████████| 1/1 [00:00<00:00, 360.89batches/s]\n",
      "Epoch 20/200 Loss: 0.5396260619163513: 100%|██████████| 1/1 [00:00<00:00, 284.90batches/s]\n",
      "Epoch 21/200 Loss: 0.5362420678138733: 100%|██████████| 1/1 [00:00<00:00, 78.76batches/s]\n",
      "Epoch 22/200 Loss: 0.5330603718757629: 100%|██████████| 1/1 [00:00<00:00, 278.16batches/s]\n",
      "Epoch 23/200 Loss: 0.5300635695457458: 100%|██████████| 1/1 [00:00<00:00, 325.85batches/s]\n",
      "Epoch 24/200 Loss: 0.5272362232208252: 100%|██████████| 1/1 [00:00<00:00, 394.46batches/s]\n",
      "Epoch 25/200 Loss: 0.5245644450187683: 100%|██████████| 1/1 [00:00<00:00, 376.51batches/s]\n",
      "Epoch 26/200 Loss: 0.5220357775688171: 100%|██████████| 1/1 [00:00<00:00, 337.05batches/s]\n",
      "Epoch 27/200 Loss: 0.5196389555931091: 100%|██████████| 1/1 [00:00<00:00, 403.07batches/s]\n",
      "Epoch 28/200 Loss: 0.5173638463020325: 100%|██████████| 1/1 [00:00<00:00, 341.89batches/s]\n",
      "Epoch 29/200 Loss: 0.5152014493942261: 100%|██████████| 1/1 [00:00<00:00, 127.23batches/s]\n",
      "Epoch 30/200 Loss: 0.5131434202194214: 100%|██████████| 1/1 [00:00<00:00, 130.94batches/s]\n",
      "Epoch 31/200 Loss: 0.5111821293830872: 100%|██████████| 1/1 [00:00<00:00, 339.21batches/s]\n",
      "Epoch 32/200 Loss: 0.5093109607696533: 100%|██████████| 1/1 [00:00<00:00, 341.78batches/s]\n",
      "Epoch 33/200 Loss: 0.5075234174728394: 100%|██████████| 1/1 [00:00<00:00, 342.59batches/s]\n",
      "Epoch 34/200 Loss: 0.5058140158653259: 100%|██████████| 1/1 [00:00<00:00, 336.70batches/s]\n",
      "Epoch 35/200 Loss: 0.5041773915290833: 100%|██████████| 1/1 [00:00<00:00, 403.57batches/s]\n",
      "Epoch 36/200 Loss: 0.5026088356971741: 100%|██████████| 1/1 [00:00<00:00, 291.29batches/s]\n",
      "Epoch 37/200 Loss: 0.5011040568351746: 100%|██████████| 1/1 [00:00<00:00, 313.87batches/s]\n",
      "Epoch 38/200 Loss: 0.4996589720249176: 100%|██████████| 1/1 [00:00<00:00, 303.50batches/s]\n",
      "Epoch 39/200 Loss: 0.49826979637145996: 100%|██████████| 1/1 [00:00<00:00, 282.48batches/s]\n",
      "Epoch 40/200 Loss: 0.49693331122398376: 100%|██████████| 1/1 [00:00<00:00, 371.05batches/s]\n",
      "Epoch 41/200 Loss: 0.495646208524704: 100%|██████████| 1/1 [00:00<00:00, 300.75batches/s]\n",
      "Epoch 42/200 Loss: 0.494405597448349: 100%|██████████| 1/1 [00:00<00:00, 341.31batches/s]\n",
      "Epoch 43/200 Loss: 0.4932089149951935: 100%|██████████| 1/1 [00:00<00:00, 321.97batches/s]\n",
      "Epoch 44/200 Loss: 0.4920535981655121: 100%|██████████| 1/1 [00:00<00:00, 126.98batches/s]\n",
      "Epoch 45/200 Loss: 0.4909372627735138: 100%|██████████| 1/1 [00:00<00:00, 165.26batches/s]\n",
      "Epoch 46/200 Loss: 0.4898580014705658: 100%|██████████| 1/1 [00:00<00:00, 294.98batches/s]\n",
      "Epoch 47/200 Loss: 0.4888136386871338: 100%|██████████| 1/1 [00:00<00:00, 384.76batches/s]\n",
      "Epoch 48/200 Loss: 0.4878023564815521: 100%|██████████| 1/1 [00:00<00:00, 321.87batches/s]\n",
      "Epoch 49/200 Loss: 0.4868224859237671: 100%|██████████| 1/1 [00:00<00:00, 347.33batches/s]\n",
      "Epoch 50/200 Loss: 0.48587241768836975: 100%|██████████| 1/1 [00:00<00:00, 373.56batches/s]\n",
      "Epoch 51/200 Loss: 0.4849506914615631: 100%|██████████| 1/1 [00:00<00:00, 359.87batches/s]\n",
      "Epoch 52/200 Loss: 0.48405590653419495: 100%|██████████| 1/1 [00:00<00:00, 353.00batches/s]\n",
      "Epoch 53/200 Loss: 0.4831867218017578: 100%|██████████| 1/1 [00:00<00:00, 352.73batches/s]\n",
      "Epoch 54/200 Loss: 0.4823419153690338: 100%|██████████| 1/1 [00:00<00:00, 321.95batches/s]\n",
      "Epoch 55/200 Loss: 0.481520414352417: 100%|██████████| 1/1 [00:00<00:00, 393.09batches/s]\n",
      "Epoch 56/200 Loss: 0.4807211458683014: 100%|██████████| 1/1 [00:00<00:00, 396.36batches/s]\n",
      "Epoch 57/200 Loss: 0.47994303703308105: 100%|██████████| 1/1 [00:00<00:00, 361.02batches/s]\n",
      "Epoch 58/200 Loss: 0.4791852533817291: 100%|██████████| 1/1 [00:00<00:00, 373.69batches/s]\n",
      "Epoch 59/200 Loss: 0.47844693064689636: 100%|██████████| 1/1 [00:00<00:00, 398.55batches/s]\n",
      "Epoch 60/200 Loss: 0.4777270555496216: 100%|██████████| 1/1 [00:00<00:00, 410.68batches/s]\n",
      "Epoch 61/200 Loss: 0.47702503204345703: 100%|██████████| 1/1 [00:00<00:00, 378.34batches/s]\n",
      "Epoch 62/200 Loss: 0.47634005546569824: 100%|██████████| 1/1 [00:00<00:00, 373.69batches/s]\n",
      "Epoch 63/200 Loss: 0.4756714403629303: 100%|██████████| 1/1 [00:00<00:00, 354.10batches/s]\n",
      "Epoch 64/200 Loss: 0.4750186502933502: 100%|██████████| 1/1 [00:00<00:00, 343.77batches/s]\n",
      "Epoch 65/200 Loss: 0.47438088059425354: 100%|██████████| 1/1 [00:00<00:00, 358.79batches/s]\n",
      "Epoch 66/200 Loss: 0.47375771403312683: 100%|██████████| 1/1 [00:00<00:00, 389.70batches/s]\n",
      "Epoch 67/200 Loss: 0.4731484651565552: 100%|██████████| 1/1 [00:00<00:00, 338.66batches/s]\n",
      "Epoch 68/200 Loss: 0.47255268692970276: 100%|██████████| 1/1 [00:00<00:00, 404.35batches/s]\n",
      "Epoch 69/200 Loss: 0.47196999192237854: 100%|██████████| 1/1 [00:00<00:00, 347.58batches/s]\n",
      "Epoch 70/200 Loss: 0.4713996350765228: 100%|██████████| 1/1 [00:00<00:00, 390.93batches/s]\n",
      "Epoch 71/200 Loss: 0.47084149718284607: 100%|██████████| 1/1 [00:00<00:00, 337.62batches/s]\n",
      "Epoch 72/200 Loss: 0.4702949523925781: 100%|██████████| 1/1 [00:00<00:00, 384.02batches/s]\n",
      "Epoch 73/200 Loss: 0.46975961327552795: 100%|██████████| 1/1 [00:00<00:00, 338.88batches/s]\n",
      "Epoch 74/200 Loss: 0.4692351818084717: 100%|██████████| 1/1 [00:00<00:00, 371.34batches/s]\n",
      "Epoch 75/200 Loss: 0.46872130036354065: 100%|██████████| 1/1 [00:00<00:00, 343.77batches/s]\n",
      "Epoch 76/200 Loss: 0.4682175815105438: 100%|██████████| 1/1 [00:00<00:00, 276.32batches/s]\n",
      "Epoch 77/200 Loss: 0.46772369742393494: 100%|██████████| 1/1 [00:00<00:00, 99.24batches/s]\n",
      "Epoch 78/200 Loss: 0.46723929047584534: 100%|██████████| 1/1 [00:00<00:00, 152.20batches/s]\n",
      "Epoch 79/200 Loss: 0.4667642116546631: 100%|██████████| 1/1 [00:00<00:00, 320.20batches/s]\n",
      "Epoch 80/200 Loss: 0.46629801392555237: 100%|██████████| 1/1 [00:00<00:00, 343.99batches/s]\n",
      "Epoch 81/200 Loss: 0.465840607881546: 100%|██████████| 1/1 [00:00<00:00, 362.08batches/s]\n",
      "Epoch 82/200 Loss: 0.4653915464878082: 100%|██████████| 1/1 [00:00<00:00, 352.37batches/s]\n",
      "Epoch 83/200 Loss: 0.46495065093040466: 100%|██████████| 1/1 [00:00<00:00, 429.92batches/s]\n",
      "Epoch 84/200 Loss: 0.4645176827907562: 100%|██████████| 1/1 [00:00<00:00, 345.18batches/s]\n",
      "Epoch 85/200 Loss: 0.464092493057251: 100%|██████████| 1/1 [00:00<00:00, 358.27batches/s]\n",
      "Epoch 86/200 Loss: 0.46367475390434265: 100%|██████████| 1/1 [00:00<00:00, 333.23batches/s]\n",
      "Epoch 87/200 Loss: 0.4632643163204193: 100%|██████████| 1/1 [00:00<00:00, 330.91batches/s]\n",
      "Epoch 88/200 Loss: 0.46286091208457947: 100%|██████████| 1/1 [00:00<00:00, 404.86batches/s]\n",
      "Epoch 89/200 Loss: 0.46246442198753357: 100%|██████████| 1/1 [00:00<00:00, 282.16batches/s]\n",
      "Epoch 90/200 Loss: 0.4620746672153473: 100%|██████████| 1/1 [00:00<00:00, 364.15batches/s]\n",
      "Epoch 91/200 Loss: 0.4616914689540863: 100%|██████████| 1/1 [00:00<00:00, 366.73batches/s]\n",
      "Epoch 92/200 Loss: 0.4613145589828491: 100%|██████████| 1/1 [00:00<00:00, 299.04batches/s]\n",
      "Epoch 93/200 Loss: 0.46094390749931335: 100%|██████████| 1/1 [00:00<00:00, 334.77batches/s]\n",
      "Epoch 94/200 Loss: 0.46057915687561035: 100%|██████████| 1/1 [00:00<00:00, 316.55batches/s]\n",
      "Epoch 95/200 Loss: 0.4602203667163849: 100%|██████████| 1/1 [00:00<00:00, 339.43batches/s]\n",
      "Epoch 96/200 Loss: 0.45986732840538025: 100%|██████████| 1/1 [00:00<00:00, 342.59batches/s]\n",
      "Epoch 97/200 Loss: 0.4595198631286621: 100%|██████████| 1/1 [00:00<00:00, 291.90batches/s]\n",
      "Epoch 98/200 Loss: 0.45917782187461853: 100%|██████████| 1/1 [00:00<00:00, 391.08batches/s]\n",
      "Epoch 99/200 Loss: 0.45884108543395996: 100%|██████████| 1/1 [00:00<00:00, 327.32batches/s]\n",
      "Epoch 100/200 Loss: 0.45850956439971924: 100%|██████████| 1/1 [00:00<00:00, 332.67batches/s]\n",
      "Epoch 101/200 Loss: 0.45818307995796204: 100%|██████████| 1/1 [00:00<00:00, 334.10batches/s]\n",
      "Epoch 102/200 Loss: 0.45786163210868835: 100%|██████████| 1/1 [00:00<00:00, 275.27batches/s]\n",
      "Epoch 103/200 Loss: 0.4575449228286743: 100%|██████████| 1/1 [00:00<00:00, 377.93batches/s]\n",
      "Epoch 104/200 Loss: 0.45723292231559753: 100%|██████████| 1/1 [00:00<00:00, 368.44batches/s]\n",
      "Epoch 105/200 Loss: 0.45692554116249084: 100%|██████████| 1/1 [00:00<00:00, 325.42batches/s]\n",
      "Epoch 106/200 Loss: 0.4566226303577423: 100%|██████████| 1/1 [00:00<00:00, 340.14batches/s]\n",
      "Epoch 107/200 Loss: 0.45632413029670715: 100%|██████████| 1/1 [00:00<00:00, 387.89batches/s]\n",
      "Epoch 108/200 Loss: 0.456030011177063: 100%|██████████| 1/1 [00:00<00:00, 374.26batches/s]\n",
      "Epoch 109/200 Loss: 0.4557400047779083: 100%|██████████| 1/1 [00:00<00:00, 342.92batches/s]\n",
      "Epoch 110/200 Loss: 0.45545411109924316: 100%|██████████| 1/1 [00:00<00:00, 374.39batches/s]\n",
      "Epoch 111/200 Loss: 0.4551723003387451: 100%|██████████| 1/1 [00:00<00:00, 369.67batches/s]\n",
      "Epoch 112/200 Loss: 0.4548943042755127: 100%|██████████| 1/1 [00:00<00:00, 359.32batches/s]\n",
      "Epoch 113/200 Loss: 0.45462027192115784: 100%|██████████| 1/1 [00:00<00:00, 367.66batches/s]\n",
      "Epoch 114/200 Loss: 0.45434990525245667: 100%|██████████| 1/1 [00:00<00:00, 360.21batches/s]\n",
      "Epoch 115/200 Loss: 0.45408329367637634: 100%|██████████| 1/1 [00:00<00:00, 387.89batches/s]\n",
      "Epoch 116/200 Loss: 0.45382022857666016: 100%|██████████| 1/1 [00:00<00:00, 404.66batches/s]\n",
      "Epoch 117/200 Loss: 0.4535607099533081: 100%|██████████| 1/1 [00:00<00:00, 346.01batches/s]\n",
      "Epoch 118/200 Loss: 0.453304648399353: 100%|██████████| 1/1 [00:00<00:00, 394.31batches/s]\n",
      "Epoch 119/200 Loss: 0.45305195450782776: 100%|██████████| 1/1 [00:00<00:00, 380.50batches/s]\n",
      "Epoch 120/200 Loss: 0.45280253887176514: 100%|██████████| 1/1 [00:00<00:00, 403.38batches/s]\n",
      "Epoch 121/200 Loss: 0.45255640149116516: 100%|██████████| 1/1 [00:00<00:00, 313.69batches/s]\n",
      "Epoch 122/200 Loss: 0.45231345295906067: 100%|██████████| 1/1 [00:00<00:00, 371.34batches/s]\n",
      "Epoch 123/200 Loss: 0.4520735740661621: 100%|██████████| 1/1 [00:00<00:00, 335.79batches/s]\n",
      "Epoch 124/200 Loss: 0.4518367350101471: 100%|██████████| 1/1 [00:00<00:00, 338.99batches/s]\n",
      "Epoch 125/200 Loss: 0.45160284638404846: 100%|██████████| 1/1 [00:00<00:00, 321.33batches/s]\n",
      "Epoch 126/200 Loss: 0.4513719975948334: 100%|██████████| 1/1 [00:00<00:00, 370.23batches/s]\n",
      "Epoch 127/200 Loss: 0.45114389061927795: 100%|██████████| 1/1 [00:00<00:00, 376.07batches/s]\n",
      "Epoch 128/200 Loss: 0.45091867446899414: 100%|██████████| 1/1 [00:00<00:00, 349.18batches/s]\n",
      "Epoch 129/200 Loss: 0.4506962299346924: 100%|██████████| 1/1 [00:00<00:00, 375.09batches/s]\n",
      "Epoch 130/200 Loss: 0.45047640800476074: 100%|██████████| 1/1 [00:00<00:00, 372.30batches/s]\n",
      "Epoch 131/200 Loss: 0.4502592086791992: 100%|██████████| 1/1 [00:00<00:00, 361.64batches/s]\n",
      "Epoch 132/200 Loss: 0.4500446319580078: 100%|██████████| 1/1 [00:00<00:00, 283.21batches/s]\n",
      "Epoch 133/200 Loss: 0.4498326778411865: 100%|██████████| 1/1 [00:00<00:00, 357.02batches/s]\n",
      "Epoch 134/200 Loss: 0.4496231973171234: 100%|██████████| 1/1 [00:00<00:00, 347.58batches/s]\n",
      "Epoch 135/200 Loss: 0.44941607117652893: 100%|██████████| 1/1 [00:00<00:00, 379.92batches/s]\n",
      "Epoch 136/200 Loss: 0.44921138882637024: 100%|██████████| 1/1 [00:00<00:00, 369.41batches/s]\n",
      "Epoch 137/200 Loss: 0.44900909066200256: 100%|██████████| 1/1 [00:00<00:00, 286.28batches/s]\n",
      "Epoch 138/200 Loss: 0.44880902767181396: 100%|██████████| 1/1 [00:00<00:00, 379.95batches/s]\n",
      "Epoch 139/200 Loss: 0.4486112892627716: 100%|██████████| 1/1 [00:00<00:00, 310.83batches/s]\n",
      "Epoch 140/200 Loss: 0.44841575622558594: 100%|██████████| 1/1 [00:00<00:00, 376.95batches/s]\n",
      "Epoch 141/200 Loss: 0.44822242856025696: 100%|██████████| 1/1 [00:00<00:00, 384.59batches/s]\n",
      "Epoch 142/200 Loss: 0.4480312764644623: 100%|██████████| 1/1 [00:00<00:00, 305.53batches/s]\n",
      "Epoch 143/200 Loss: 0.4478421211242676: 100%|██████████| 1/1 [00:00<00:00, 375.93batches/s]\n",
      "Epoch 144/200 Loss: 0.4476550817489624: 100%|██████████| 1/1 [00:00<00:00, 343.06batches/s]\n",
      "Epoch 145/200 Loss: 0.4474700391292572: 100%|██████████| 1/1 [00:00<00:00, 362.58batches/s]\n",
      "Epoch 146/200 Loss: 0.44728705286979675: 100%|██████████| 1/1 [00:00<00:00, 363.24batches/s]\n",
      "Epoch 147/200 Loss: 0.4471060037612915: 100%|██████████| 1/1 [00:00<00:00, 294.98batches/s]\n",
      "Epoch 148/200 Loss: 0.4469268023967743: 100%|██████████| 1/1 [00:00<00:00, 365.10batches/s]\n",
      "Epoch 149/200 Loss: 0.4467494785785675: 100%|██████████| 1/1 [00:00<00:00, 306.83batches/s]\n",
      "Epoch 150/200 Loss: 0.4465740919113159: 100%|██████████| 1/1 [00:00<00:00, 381.27batches/s]\n",
      "Epoch 151/200 Loss: 0.4464004933834076: 100%|██████████| 1/1 [00:00<00:00, 380.23batches/s]\n",
      "Epoch 152/200 Loss: 0.44622859358787537: 100%|██████████| 1/1 [00:00<00:00, 291.96batches/s]\n",
      "Epoch 153/200 Loss: 0.4460585415363312: 100%|██████████| 1/1 [00:00<00:00, 343.65batches/s]\n",
      "Epoch 154/200 Loss: 0.4458901882171631: 100%|██████████| 1/1 [00:00<00:00, 326.91batches/s]\n",
      "Epoch 155/200 Loss: 0.4457235336303711: 100%|██████████| 1/1 [00:00<00:00, 353.23batches/s]\n",
      "Epoch 156/200 Loss: 0.4455585181713104: 100%|██████████| 1/1 [00:00<00:00, 320.81batches/s]\n",
      "Epoch 157/200 Loss: 0.4453950822353363: 100%|██████████| 1/1 [00:00<00:00, 264.14batches/s]\n",
      "Epoch 158/200 Loss: 0.4452333152294159: 100%|██████████| 1/1 [00:00<00:00, 352.23batches/s]\n",
      "Epoch 159/200 Loss: 0.44507312774658203: 100%|██████████| 1/1 [00:00<00:00, 277.93batches/s]\n",
      "Epoch 160/200 Loss: 0.44491443037986755: 100%|██████████| 1/1 [00:00<00:00, 356.63batches/s]\n",
      "Epoch 161/200 Loss: 0.4447573125362396: 100%|██████████| 1/1 [00:00<00:00, 373.42batches/s]\n",
      "Epoch 162/200 Loss: 0.4446016252040863: 100%|██████████| 1/1 [00:00<00:00, 330.68batches/s]\n",
      "Epoch 163/200 Loss: 0.44444751739501953: 100%|██████████| 1/1 [00:00<00:00, 339.89batches/s]\n",
      "Epoch 164/200 Loss: 0.4442947208881378: 100%|██████████| 1/1 [00:00<00:00, 320.74batches/s]\n",
      "Epoch 165/200 Loss: 0.4441434442996979: 100%|██████████| 1/1 [00:00<00:00, 372.43batches/s]\n",
      "Epoch 166/200 Loss: 0.44399356842041016: 100%|██████████| 1/1 [00:00<00:00, 358.15batches/s]\n",
      "Epoch 167/200 Loss: 0.4438450038433075: 100%|██████████| 1/1 [00:00<00:00, 423.75batches/s]\n",
      "Epoch 168/200 Loss: 0.44369781017303467: 100%|██████████| 1/1 [00:00<00:00, 344.95batches/s]\n",
      "Epoch 169/200 Loss: 0.4435519874095917: 100%|██████████| 1/1 [00:00<00:00, 347.73batches/s]\n",
      "Epoch 170/200 Loss: 0.4434073865413666: 100%|██████████| 1/1 [00:00<00:00, 363.90batches/s]\n",
      "Epoch 171/200 Loss: 0.4432641565799713: 100%|██████████| 1/1 [00:00<00:00, 327.76batches/s]\n",
      "Epoch 172/200 Loss: 0.44312214851379395: 100%|██████████| 1/1 [00:00<00:00, 366.57batches/s]\n",
      "Epoch 173/200 Loss: 0.4429813325405121: 100%|██████████| 1/1 [00:00<00:00, 342.00batches/s]\n",
      "Epoch 174/200 Loss: 0.4428417682647705: 100%|██████████| 1/1 [00:00<00:00, 358.18batches/s]\n",
      "Epoch 175/200 Loss: 0.4427034556865692: 100%|██████████| 1/1 [00:00<00:00, 359.84batches/s]\n",
      "Epoch 176/200 Loss: 0.44256630539894104: 100%|██████████| 1/1 [00:00<00:00, 283.53batches/s]\n",
      "Epoch 177/200 Loss: 0.4424303472042084: 100%|██████████| 1/1 [00:00<00:00, 133.12batches/s]\n",
      "Epoch 178/200 Loss: 0.44229546189308167: 100%|██████████| 1/1 [00:00<00:00, 195.00batches/s]\n",
      "Epoch 179/200 Loss: 0.4421617090702057: 100%|██████████| 1/1 [00:00<00:00, 288.78batches/s]\n",
      "Epoch 180/200 Loss: 0.4420291483402252: 100%|██████████| 1/1 [00:00<00:00, 352.37batches/s]\n",
      "Epoch 181/200 Loss: 0.4418976306915283: 100%|██████████| 1/1 [00:00<00:00, 361.92batches/s]\n",
      "Epoch 182/200 Loss: 0.44176721572875977: 100%|██████████| 1/1 [00:00<00:00, 390.31batches/s]\n",
      "Epoch 183/200 Loss: 0.4416378438472748: 100%|██████████| 1/1 [00:00<00:00, 377.63batches/s]\n",
      "Epoch 184/200 Loss: 0.441509485244751: 100%|██████████| 1/1 [00:00<00:00, 317.56batches/s]\n",
      "Epoch 185/200 Loss: 0.44138213992118835: 100%|██████████| 1/1 [00:00<00:00, 328.94batches/s]\n",
      "Epoch 186/200 Loss: 0.4412558078765869: 100%|██████████| 1/1 [00:00<00:00, 426.25batches/s]\n",
      "Epoch 187/200 Loss: 0.44113054871559143: 100%|██████████| 1/1 [00:00<00:00, 362.58batches/s]\n",
      "Epoch 188/200 Loss: 0.44100627303123474: 100%|██████████| 1/1 [00:00<00:00, 393.83batches/s]\n",
      "Epoch 189/200 Loss: 0.4408828318119049: 100%|██████████| 1/1 [00:00<00:00, 386.86batches/s]\n",
      "Epoch 190/200 Loss: 0.44076040387153625: 100%|██████████| 1/1 [00:00<00:00, 354.73batches/s]\n",
      "Epoch 191/200 Loss: 0.4406389892101288: 100%|██████████| 1/1 [00:00<00:00, 376.64batches/s]\n",
      "Epoch 192/200 Loss: 0.44051846861839294: 100%|██████████| 1/1 [00:00<00:00, 403.41batches/s]\n",
      "Epoch 193/200 Loss: 0.4403986930847168: 100%|██████████| 1/1 [00:00<00:00, 355.24batches/s]\n",
      "Epoch 194/200 Loss: 0.4402800500392914: 100%|██████████| 1/1 [00:00<00:00, 430.67batches/s]\n",
      "Epoch 195/200 Loss: 0.4401620924472809: 100%|██████████| 1/1 [00:00<00:00, 335.92batches/s]\n",
      "Epoch 196/200 Loss: 0.4400451183319092: 100%|██████████| 1/1 [00:00<00:00, 352.26batches/s]\n",
      "Epoch 197/200 Loss: 0.4399290084838867: 100%|██████████| 1/1 [00:00<00:00, 345.55batches/s]\n",
      "Epoch 198/200 Loss: 0.43981361389160156: 100%|██████████| 1/1 [00:00<00:00, 325.42batches/s]\n",
      "Epoch 199/200 Loss: 0.4396991729736328: 100%|██████████| 1/1 [00:00<00:00, 381.23batches/s]\n",
      "Epoch 200/200 Loss: 0.43958553671836853: 100%|██████████| 1/1 [00:00<00:00, 336.70batches/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk0AAAGGCAYAAABmPbWyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCCGEA6TRJIQQQgjhAGk0CSGEEEI44P8BXUlc23uONGkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1274d8128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy at 0.8235294222831726\n"
     ]
    }
   ],
   "source": [
    "# Trainning neural network\n",
    "\n",
    "# Change if you have memory restrictions\n",
    "batch_size = 200\n",
    "\n",
    "# Find the best parameters for each configuration\n",
    "epochs = 200\n",
    "learning_rate = 0.2\n",
    "\n",
    "# Gradient Descent\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)    \n",
    "\n",
    "# The accuracy measured against the validation set\n",
    "validation_accuracy = 0.0\n",
    "\n",
    "# Measurements use for graphing loss and accuracy\n",
    "log_batch_step = 10\n",
    "batches = []\n",
    "loss_batch = []\n",
    "train_acc_batch = []\n",
    "valid_acc_batch = []\n",
    "v_loss = 0\n",
    "\n",
    "with tf.Session() as session:\n",
    "    session.run(init)\n",
    "    batch_count = int(math.ceil(len(train_features)/batch_size))\n",
    "\n",
    "    for epoch_i in range(epochs):     \n",
    "        # Progress bar\n",
    "        batches_pbar = tqdm(range(batch_count), desc='Epoch {:>2}/{} Loss: {}'.format(epoch_i+1, epochs, v_loss), unit='batches')\n",
    "        \n",
    "        # The training cycle\n",
    "        for batch_i in batches_pbar:\n",
    "            # Get a batch of training features and labels\n",
    "            batch_start = batch_i*batch_size\n",
    "            batch_features = train_features[batch_start:batch_start + batch_size].as_matrix()\n",
    "            batch_labels = pd.get_dummies(train_labels[batch_start:batch_start + batch_size]).as_matrix()\n",
    "\n",
    "            # Run optimizer and get loss\n",
    "            _, v_loss = session.run(\n",
    "                [optimizer, loss],\n",
    "                feed_dict={features: batch_features, labels: batch_labels})\n",
    "\n",
    "            # Log every count batches\n",
    "            if not batch_i % log_batch_step:\n",
    "                # Calculate Training and Validation accuracy\n",
    "                training_accuracy = session.run(accuracy, feed_dict=train_feed_dict)\n",
    "                validation_accuracy = session.run(accuracy, feed_dict=valid_feed_dict)\n",
    "\n",
    "                # Log batches\n",
    "                previous_batch = batches[-1] if batches else 0\n",
    "                batches.append(log_batch_step + previous_batch)\n",
    "                loss_batch.append(v_loss)\n",
    "                train_acc_batch.append(training_accuracy)\n",
    "                valid_acc_batch.append(validation_accuracy)\n",
    "\n",
    "        # Check accuracy against Validation data\n",
    "        validation_accuracy = session.run(accuracy, feed_dict=valid_feed_dict)\n",
    "\n",
    "\n",
    "loss_plot = plt.subplot(211)\n",
    "loss_plot.set_title('Loss')\n",
    "loss_plot.plot(batches, loss_batch, 'g')\n",
    "loss_plot.set_xlim([batches[0], batches[-1]])\n",
    "acc_plot = plt.subplot(212)\n",
    "acc_plot.set_title('Accuracy')\n",
    "acc_plot.plot(batches, train_acc_batch, 'r', label='Training Accuracy')\n",
    "acc_plot.plot(batches, valid_acc_batch, 'x', label='Validation Accuracy')\n",
    "acc_plot.set_ylim([0, 1.0])\n",
    "acc_plot.set_xlim([batches[0], batches[-1]])\n",
    "acc_plot.legend(loc=4)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('Validation accuracy at {}'.format(validation_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate file to kaggle submission\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    indexes = new_data_test.index.values\n",
    "    test_logits = logits.eval(test_feed_dict)\n",
    "    predictions = tf.argmax(test_logits, dimension=1).eval()\n",
    "\n",
    "    with open(\"submission.csv\", \"w\") as f:\n",
    "        f.write(\"PassengerId,Survived\\n\")\n",
    "        for index, prediction in zip(indexes, predictions):\n",
    "            f.write(\"{0},{1}\\n\".format(index, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
